{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U \\\n",
    "    langgraph \\\n",
    "    langchain-openai \\\n",
    "    requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import logging\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "# IPython display utilities\n",
    "from IPython.display import Image, Markdown, display\n",
    "\n",
    "# LangChain core components\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LangGraph components\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"o3-mini\",\n",
    "    max_tokens=None,\n",
    "    max_retries=6,\n",
    "    stop=None,\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hi Jacob, I'm ChatGPT! What's on your mind today?\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 343, 'prompt_tokens': 16, 'total_tokens': 359, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 320, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o3-mini-2025-01-31', 'system_fingerprint': 'fp_8bcaa0ca21', 'finish_reason': 'stop', 'logprobs': None} id='run-2622e78b-5792-40c6-af90-024af0f3a853-0' usage_metadata={'input_tokens': 16, 'output_tokens': 343, 'total_tokens': 359, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 320}}\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke([HumanMessage(content=\"Hi my name is Jacob, what's your name?\")])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name=\"stack-python-answers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/wooyakob/Desktop/03-mini-hackathon/stack-python-answers.csv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   question_id                                     question_title  \\\n",
      "0       108892  Is there something like 'autotest' for Python ...   \n",
      "1       212358                Binary search (bisection) in Python   \n",
      "2       425990                               Django on IronPython   \n",
      "3       434287               How to iterate over a list in chunks   \n",
      "4       448271                           What is __init__.py for?   \n",
      "\n",
      "                                       question_body  \\\n",
      "0  <p>Basically, growl notifications (or other ca...   \n",
      "1  <p>Is there a library function that performs b...   \n",
      "2  <p>I am interested in getting an install of Dj...   \n",
      "3  <p>I have a Python script which takes as input...   \n",
      "4  <p>What is <a href=\"https://docs.python.org/3/...   \n",
      "\n",
      "           question_creation_date  question_score  view_count  \\\n",
      "0  2008-09-20 18:07:40.597000 UTC              44        9932   \n",
      "1  2008-10-17 14:23:17.630000 UTC             205      207138   \n",
      "2  2009-01-08 21:16:01.737000 UTC              52       12247   \n",
      "3  2009-01-12 02:48:22.960000 UTC             633      211562   \n",
      "4  2009-01-15 20:09:09.707000 UTC            3338     1948967   \n",
      "\n",
      "                                     tags  answer_id  \\\n",
      "0                          python|testing    9461979   \n",
      "1          python|binary-search|bisection    2233940   \n",
      "2                python|django|ironpython     518317   \n",
      "3   python|list|loops|optimization|chunks     434328   \n",
      "4  python|module|package|python-packaging     448279   \n",
      "\n",
      "                                         answer_body  \\\n",
      "0  <p>I found <a href=\"https://github.com/gfxmonk...   \n",
      "1  <p><code>bisect_left</code> finds the first po...   \n",
      "2  <p>Besides the Jeff Hardy blog post on <a href...   \n",
      "3  <pre><code>def chunker(seq, size):\\n    return...   \n",
      "4  <p>It used to be a required part of a package ...   \n",
      "\n",
      "             answer_creation_date  answer_score  answer_owner_user_id  \n",
      "0  2012-02-27 08:28:14.297000 UTC            28                 912.0  \n",
      "1  2010-02-10 02:05:27.873000 UTC           268              125349.0  \n",
      "2  2009-02-05 22:40:08.427000 UTC            26               62957.0  \n",
      "3  2009-01-12 03:10:17.987000 UTC           554               17160.0  \n",
      "4  2009-01-15 20:13:24.987000 UTC          1874               39057.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('stack-python-answers.csv', sep=',')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_experimental'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_experimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent_toolkits\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_pandas_dataframe_agent\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AgentType\n\u001b[1;32m      3\u001b[0m agent \u001b[38;5;241m=\u001b[39m create_pandas_dataframe_agent(llm, product_df, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dangerous_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_experimental'"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "agent = create_pandas_dataframe_agent(llm, product_df, verbose=True, allow_dangerous_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agent's memory\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "# Initialize agent memory\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Set logging level to ERROR to filter warnings\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
